{"classifiers": ["Development Status :: 4 - Beta", "License :: OSI Approved :: MIT License", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3.5"], "extensions": {"python.details": {"contacts": [{"email": "maclaurin@physics.harvard.edu, duvenaud@cs.toronto.edu, mattjj@csail.mit.edu", "name": "Dougal Maclaurin and David Duvenaud and Matthew Johnson", "role": "author"}], "document_names": {"description": "DESCRIPTION.rst"}, "project_urls": {"Home": "https://github.com/HIPS/autograd"}}}, "extras": [], "generator": "bdist_wheel (0.30.0)", "keywords": ["Automatic", "differentiation", "backpropagation", "gradients", "machine", "learning", "optimization", "neural", "networks", "Python", "Numpy", "Scipy"], "license": "MIT", "metadata_version": "2.0", "name": "autograd", "run_requires": [{"requires": ["future (>=0.15.2)", "numpy (>=1.12)"]}], "summary": "Efficiently computes derivatives of numpy code.", "version": "1.3"}